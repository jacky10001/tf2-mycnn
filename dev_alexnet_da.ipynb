{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet\n",
    "\n",
    "以前，神經網路 (就是現在的深度學習) 一直無法取得重大突破，其因主要有兩點：\n",
    "\n",
    "- LeNet 在資料量小時，表現很好，但是在大資料量無法有效訓練，導致神經網路無法比其他機器學習演算法表現更好\n",
    "- 當時硬體規格並沒有像現在強大，而偏偏神經網路的訓練需要仰賴大量運算，所以許多研究都轉往其他學習演算法\n",
    "\n",
    "AlexNet 可以視為 LeNet 的強化版，也讓 CNN 真正備受到重視，其特點如下：\n",
    "\n",
    "- 利用 GPU 來大幅加速神經網路的訓練\n",
    "- 使用 5 層的卷積層，來擬合更複雜的資料集 (ImageNet)\n",
    "- 激活函數改成 Rectified Linear Unit (ReLU)\n",
    "- 全連接層加入 Dropout\n",
    "- 使用 Local Response Normalization 對歸一化卷積層的特徵圖 (我用 Batch Normalization 代替，LRN 沒啥卵用..)\n",
    "- 使用資料擴增增加資料多樣性\n",
    "\n",
    "### Note\n",
    "\n",
    "這裡其實我覺得很重要的思想在於，如何讓資料有效被神經網路學習並識別，傳統上使用其他機器學習演算法，都必須仰賴對於資料的特徵處理，而越高階的特徵，人類越難處理，也必須要有更多先驗知識，才能獲得正確資料特徵。  \n",
    "從這個角度來看，如果能夠處理好資料，使資料能夠\"正確\"，那 CNN 的表現得確可以比其他演算法更加強效，因為 CNN 對於資料特徵的理解是通過數據學習而來，而且現在也有許多更複雜、擬合能力更強的架構出現，能夠\"深層\"學習到資料特徵，跟其他學習演算法比起來，那些其實都還只是停留在\"淺層\"學習，說不定哪天其他領域有了重大突破又把深度學習比下去了。\n",
    "\n",
    "> 題外話: 這些單純是個人理解，資訊工程博大精深，對於任何數學、推導一概不懂XD，小弟只是根據各大教材得到的結論\n",
    "\n",
    "### Reference\n",
    "\n",
    "[1] Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). [Imagenet classification with deep convolutional neural networks](https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf). In Advances in neural information processing systems (pp. 1097-1105)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 引入相關python模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mycnn import AlexNet\n",
    "from mycnn import utils\n",
    "from mycnn import data\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自動下載貓狗資料集\n",
    "\n",
    "從 Microsoft Download Center 下載 Kaggle Cats and Dogs Dataset  \n",
    "會自動在工作路徑底下建立資料夾，並建立相關的資料集檔案結構  \n",
    "也會檢查路徑底下是否已經有建立完成檔案，避免重複下載及建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cats_vs_dogs_from_MSCenter('./datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 呼叫mycnn.data的資料擴增Dataset實例\n",
    "\n",
    "利用Keras API中的`preprocessing`模組的`image_dataset_from_directory`  \n",
    "用此函數來建立貓狗的資料集，此函數將會回傳`tf.data.Dataset`的實例  \n",
    "接著使用`map`函式來重新縮放(正規化)資料區間至 [0, 1]\n",
    "\n",
    "```\n",
    "mycnn.data.generate_classification_dataset\n",
    "\n",
    "參數名稱            型態    說明\n",
    "directory        : str   : 資料路徑 (子資料夾為類別)\n",
    "image_size       : tuple : 影像大小\n",
    "batch_size       : int   : 批次大小\n",
    "shuffle_filepath : bool  : 打亂檔案路徑順序\n",
    "validation_split : float : 分離驗證集的比例\n",
    "**augdict        : int   : 資料擴增設定\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augdict = {\n",
    "    \"flip_h\": {},\n",
    "    \"flip_v\": {},\n",
    "    \"rotate\": {},\n",
    "    # \"hue\": {\"val\": 0.1},\n",
    "    \"brightness\": {\"val\": 0.75},\n",
    "    # \"saturation\": {\"lower\": 0.6, \"upper\": 1.6},\n",
    "    # \"contrast\": {\"lower\": 0.7, \"upper\": 1.3},\n",
    "    \"zoom_scale\": {\"scale_minval\": 0.75, \"scale_maxval\": 1.25},\n",
    "}\n",
    "\n",
    "train_dataset, valid_dataset = data.generate_classification_dataset(\n",
    "    './Datasets/DogsVsCats/train',\n",
    "    image_size=(227,227),\n",
    "    batch_size=30,\n",
    "    subtract_mean=128,\n",
    "    divide_stddev=128,\n",
    "    shuffle_filepath=True,\n",
    "    shuffle_dataset=True,\n",
    "    validation_split=0.2,\n",
    "    **augdict\n",
    ")\n",
    "\n",
    "train_file_paths = train_dataset.file_paths\n",
    "valid_file_paths = valid_dataset.file_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 檢查原始資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "file_path = valid_file_paths[idx]\n",
    "print(file_path)\n",
    "image = cv2.imread(file_path)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "resized_image = cv2.resize(image, (227,227))\n",
    "plt.imshow(resized_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入模型\n",
    "\n",
    "```\n",
    "參數名稱       型態    說明\n",
    "input_shape : tuple : 輸入影像形狀\n",
    "classes_num : int   : 輸出類別數量\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = AlexNet(classes_num=2)\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置訓練參數\n",
    "\n",
    "```\n",
    "參數名稱      型態                         說明\n",
    "logdir     : str                        : 儲存路徑\n",
    "epochs     : int                        : 訓練次數\n",
    "batch_size : int                        : 批次大小 (註:此設定需與image_dataset_from_directory的批次大小一致)\n",
    "optimizer  : str or tf.keras.optimizers : 優化函數\n",
    "loss       : str or tf.keras.loss       : 損失函數\n",
    "metrics    : list                       : 評估函數清單\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.setup_training(\n",
    "    'log_alexnet_da',\n",
    "    epochs=50,\n",
    "    batch_size=50,  # batch size depend on ImageGenerator\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "cbks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=0.8, patience=3,\n",
    "        min_lr=0.00001,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=5,\n",
    "        verbose=1\n",
    "    ),\n",
    "]\n",
    "cnn.add_callbacks(cbks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 開始訓練\n",
    "\n",
    "輸入參數分別為訓練資料集、驗證資料集的實例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.train_dataset(train_dataset, valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 繪製訓練過程曲線\n",
    "\n",
    "可以用來確認權重是否有收斂的趨勢、檢查是否有過擬合狀況"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.show_history([\"loss\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用測試資料來確認模型對於新資料的效能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.eval_dataset(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用confusion matrix來更進一步確認分類性能\n",
    "\n",
    "- 預測測試資料的分數 (基於softmax函數計算機率分布)\n",
    "- 使用`argmax`將分數轉成類別ID\n",
    "- 輸出分類報告 (印出confusion matrix、分類報告；輸出完整報表)\n",
    "- 繪製confusion matrix，分為recall、precision\n",
    "\n",
    "> Note:  \n",
    "recall: 召回率，在所有GT中，真正預測出TP的指標  \n",
    "precision: 精確率，在所有預測結果中，真正為TP的指標  \n",
    "(GT: 真實情況；TP: 正樣本)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    './datasets/DogsVsCats/train',\n",
    "    image_size=(227,227),\n",
    "    batch_size=20,\n",
    "    label_mode=\"categorical\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=10\n",
    ")\n",
    "pred_dataset = pred_dataset.map(lambda x, y: (x/255., y))\n",
    "\n",
    "pr_score = None\n",
    "pr_label = None\n",
    "gt_label = None\n",
    "for ind, batch_set in enumerate(pred_dataset):\n",
    "    batch_im, batch_gt = batch_set\n",
    "    batch_pr = cnn.pred(batch_im.numpy())\n",
    "    if ind == 0:\n",
    "        pr_score = batch_pr\n",
    "        pr_label = batch_pr.argmax(axis=-1)\n",
    "        gt_label = batch_gt.numpy().argmax(axis=-1)\n",
    "    else:\n",
    "        pr_score = np.concatenate([pr_score, batch_pr])\n",
    "        pr_label = np.concatenate([pr_label, batch_pr.argmax(axis=-1)])\n",
    "        gt_label = np.concatenate([gt_label, batch_gt.numpy().argmax(axis=-1)])\n",
    "\n",
    "target_names = [\"Cats\", \"Dogs\"]\n",
    "\n",
    "report = utils.export_classification_report(\n",
    "    gt_label, pr_label, pr_score,\n",
    "    target_names=target_names,\n",
    "    logpath=cnn.logdir\n",
    ")\n",
    "\n",
    "cm = report[\"confusion_matrix\"]\n",
    "cm_precision = cm/cm.sum(axis=0)\n",
    "cm_recall = cm/cm.sum(axis=1)\n",
    "utils.plot_confusion_matrix(cm_recall, target_names, cnn.logdir, title='Confusion Matrix (recall)')\n",
    "utils.plot_confusion_matrix(cm_precision, target_names, cnn.logdir, title='Confusion Matrix (precision)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 預測單筆資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "file_path = valid_file_paths[idx]\n",
    "print(file_path)\n",
    "image = cv2.imread(file_path)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "resized_image = cv2.resize(image, (227,227))\n",
    "plt.imshow(resized_image)\n",
    "plt.show()\n",
    "\n",
    "batch_one_image = np.expand_dims(resized_image, axis=0)\n",
    "batch_one_image = np.expand_dims(batch_one_image, axis=-1)\n",
    "print(batch_one_image.shape)\n",
    "\n",
    "pr_sc = cnn.predict(batch_one_image)\n",
    "pr_lb = pr_sc.argmax(axis=-1)\n",
    "print(\"Score:\")\n",
    "print(pr_sc[0])\n",
    "print(\"Label:\", pr_lb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c369c7a0bd18095d69cc6bcfdfaf93c8e305f9651a20b05d28ea042855c27d0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tf2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
