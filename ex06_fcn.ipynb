{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 引入相關python模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mycnn import FCN8, FCN16, FCN32\n",
    "from mycnn import data\n",
    "from mycnn import losses\n",
    "from mycnn import utils\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自動建立VOC分割資料集\n",
    "\n",
    "會自動在工作路徑底下建立資料夾，並建立相關的資料集檔案結構  \n",
    "也會檢查路徑底下是否已經有建立完成檔案，避免重複下載及建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already download tar file.\n",
      "Already Uutar tar file.\n",
      "Make some folders.\n",
      "Get data list.\n",
      "Already made dataset.\n"
     ]
    }
   ],
   "source": [
    "data.download_pascal_voc_dataset(\n",
    "    \"./datasets\"\n",
    ")\n",
    "data.make_voc_segment_dataset(\n",
    "    \"./datasets/VOC/VOCdevkit/VOC2012\",\n",
    "    \"./datasets\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 `tf.data.Dataset` 來載入分割資料集\n",
    "\n",
    "使用自建的 Dataset 實例來讀取影像、遮罩(mask)，並處理成 CNN 可以訓練的形式\n",
    "\n",
    "```\n",
    "mycnn.data.generate_segmentation_dataset\n",
    "\n",
    "參數名稱            型態    說明\n",
    "directory        : str   : 資料路徑 (子資料夾為類別)\n",
    "image_size       : tuple : 影像大小\n",
    "batch_size       : int   : 批次大小\n",
    "subtract_mean    : float : 減去影像的均值，使其正規化\n",
    "divide_stddev    : float : 除去影像標準差，使其正規化\n",
    "shuffle_filepath : bool  : 打亂資料檔案路徑順序\n",
    "shuffle_dataset  : bool  : 打亂資料讀取順序\n",
    "validation_split : float : 分離驗證集的比例\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read segmentation dataset.\n",
      "\n",
      "Found 2913 image files and 2913.\n",
      "Using 2621 files for training.\n",
      "Using 292 files for validation.\n",
      "\n",
      "train - RGB image - Not use data augmentation.\n",
      "Rescale value to [0.0, 1.0].\n",
      "\n",
      "valid - RGB image - Not use data augmentation.\n",
      "Rescale value to [0.0, 1.0].\n"
     ]
    }
   ],
   "source": [
    "train_dataset, valid_dataset = data.generate_segmentation_dataset(\n",
    "    \"./datasets/VOCSegmentation/train\",\n",
    "    image_size=(224,224),\n",
    "    batch_size=4,\n",
    "    subtract_mean=0,\n",
    "    divide_stddev=255,\n",
    "    shuffle_filepath=True,\n",
    "    # shuffle_dataset=True,\n",
    "    validation_split=0.1,\n",
    ")\n",
    "train_image_paths = train_dataset.image_paths\n",
    "valid_image_paths = valid_dataset.image_paths\n",
    "train_mask_paths = train_dataset.mask_paths\n",
    "valid_mask_paths = valid_dataset.mask_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 檢查原始資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, m in valid_dataset.take(1):\n",
    "#     bi = i\n",
    "#     bm = m\n",
    "# print(bi.shape)\n",
    "# print(bm.shape)\n",
    "\n",
    "# idx = 0\n",
    "# plt.subplot(121)\n",
    "# plt.imshow(bi[idx])\n",
    "# plt.subplot(122)\n",
    "# plt.imshow(bm[idx,...,0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入模型\n",
    "\n",
    "```\n",
    "參數名稱       型態    說明\n",
    "input_shape : tuple : 輸入影像形狀\n",
    "classes_num : int   : 輸出類別數量\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"FCN8\"\n",
      "________________________________________________________________________________________________________________________\n",
      "Layer (type)                           Output Shape               Param #       Connected to                            \n",
      "========================================================================================================================\n",
      "image (InputLayer)                     [(None, 224, 224, 3)]      0                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)                  (None, 224, 224, 64)       1792          image[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "block1_bn1 (BatchNormalization)        (None, 224, 224, 64)       256           block1_conv1[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block1_relu1 (ReLU)                    (None, 224, 224, 64)       0             block1_bn1[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)                  (None, 224, 224, 64)       36928         block1_relu1[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block1_bn2 (BatchNormalization)        (None, 224, 224, 64)       256           block1_conv2[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block1_relu2 (ReLU)                    (None, 224, 224, 64)       0             block1_bn2[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)             (None, 112, 112, 64)       0             block1_relu2[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)                  (None, 112, 112, 128)      73856         block1_pool[0][0]                       \n",
      "________________________________________________________________________________________________________________________\n",
      "block2_bn1 (BatchNormalization)        (None, 112, 112, 128)      512           block2_conv1[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block2_relu1 (ReLU)                    (None, 112, 112, 128)      0             block2_bn1[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)                  (None, 112, 112, 128)      147584        block2_relu1[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block2_bn2 (BatchNormalization)        (None, 112, 112, 128)      512           block2_conv2[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block2_relu2 (ReLU)                    (None, 112, 112, 128)      0             block2_bn2[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)             (None, 56, 56, 128)        0             block2_relu2[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)                  (None, 56, 56, 256)        295168        block2_pool[0][0]                       \n",
      "________________________________________________________________________________________________________________________\n",
      "block3_bn1 (BatchNormalization)        (None, 56, 56, 256)        1024          block3_conv1[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block3_relu1 (ReLU)                    (None, 56, 56, 256)        0             block3_bn1[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)                  (None, 56, 56, 256)        590080        block3_relu1[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block3_bn2 (BatchNormalization)        (None, 56, 56, 256)        1024          block3_conv2[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block3_relu2 (ReLU)                    (None, 56, 56, 256)        0             block3_bn2[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)                  (None, 56, 56, 256)        590080        block3_relu2[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block3_bn3 (BatchNormalization)        (None, 56, 56, 256)        1024          block3_conv3[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block3_relu3 (ReLU)                    (None, 56, 56, 256)        0             block3_bn3[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)             (None, 28, 28, 256)        0             block3_relu3[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)                  (None, 28, 28, 512)        1180160       block3_pool[0][0]                       \n",
      "________________________________________________________________________________________________________________________\n",
      "block4_bn1 (BatchNormalization)        (None, 28, 28, 512)        2048          block4_conv1[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block4_relu1 (ReLU)                    (None, 28, 28, 512)        0             block4_bn1[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)                  (None, 28, 28, 512)        2359808       block4_relu1[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block4_bn2 (BatchNormalization)        (None, 28, 28, 512)        2048          block4_conv2[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block4_relu2 (ReLU)                    (None, 28, 28, 512)        0             block4_bn2[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)                  (None, 28, 28, 512)        2359808       block4_relu2[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block4_bn3 (BatchNormalization)        (None, 28, 28, 512)        2048          block4_conv3[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block4_relu3 (ReLU)                    (None, 28, 28, 512)        0             block4_bn3[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)             (None, 14, 14, 512)        0             block4_relu3[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)                  (None, 14, 14, 512)        2359808       block4_pool[0][0]                       \n",
      "________________________________________________________________________________________________________________________\n",
      "block5_bn1 (BatchNormalization)        (None, 14, 14, 512)        2048          block5_conv1[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block5_relu1 (ReLU)                    (None, 14, 14, 512)        0             block5_bn1[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)                  (None, 14, 14, 512)        2359808       block5_relu1[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block5_bn2 (BatchNormalization)        (None, 14, 14, 512)        2048          block5_conv2[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block5_relu2 (ReLU)                    (None, 14, 14, 512)        0             block5_bn2[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)                  (None, 14, 14, 512)        2359808       block5_relu2[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block5_bn3 (BatchNormalization)        (None, 14, 14, 512)        2048          block5_conv3[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block5_relu3 (ReLU)                    (None, 14, 14, 512)        0             block5_bn3[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)             (None, 7, 7, 512)          0             block5_relu3[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "fc_conv1 (Conv2D)                      (None, 7, 7, 512)          12845568      block5_pool[0][0]                       \n",
      "________________________________________________________________________________________________________________________\n",
      "fc_bn1 (BatchNormalization)            (None, 7, 7, 512)          2048          fc_conv1[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "fc_relu1 (ReLU)                        (None, 7, 7, 512)          0             fc_bn1[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "fc_dropout (Dropout)                   (None, 7, 7, 512)          0             fc_relu1[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "fc_conv2 (Conv2D)                      (None, 7, 7, 512)          262656        fc_dropout[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "fc_bn2 (BatchNormalization)            (None, 7, 7, 512)          2048          fc_conv2[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "fc_relu2 (ReLU)                        (None, 7, 7, 512)          0             fc_bn2[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "fcn8_conv1 (Conv2D)                    (None, 7, 7, 21)           10773         fc_relu2[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "fcn8_conv1t (Conv2DTranspose)          (None, 14, 14, 21)         1764          fcn8_conv1[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "fcn8_pool4 (Conv2D)                    (None, 14, 14, 21)         10773         block4_pool[0][0]                       \n",
      "________________________________________________________________________________________________________________________\n",
      "fcn8_up_x2 (Add)                       (None, 14, 14, 21)         0             fcn8_conv1t[0][0]                       \n",
      "                                                                                fcn8_pool4[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "fcn8_conv2 (Conv2D)                    (None, 14, 14, 21)         462           fcn8_up_x2[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "fcn8_conv2t (Conv2DTranspose)          (None, 28, 28, 21)         1764          fcn8_conv2[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "fcn8_pool3 (Conv2D)                    (None, 28, 28, 21)         5397          block3_pool[0][0]                       \n",
      "________________________________________________________________________________________________________________________\n",
      "fcn8_up_x4 (Add)                       (None, 28, 28, 21)         0             fcn8_conv2t[0][0]                       \n",
      "                                                                                fcn8_pool3[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "fcn8_conv3 (Conv2D)                    (None, 28, 28, 21)         462           fcn8_up_x4[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "fcn8_conv3t (Conv2DTranspose)          (None, 224, 224, 21)       28224         fcn8_conv3[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "predictions (Softmax)                  (None, 224, 224, 21)       0             fcn8_conv3t[0][0]                       \n",
      "========================================================================================================================\n",
      "Total params: 27,903,523\n",
      "Trainable params: 27,893,027\n",
      "Non-trainable params: 10,496\n",
      "________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = FCN8(classes_num=21, filters_list=[64,128,256,512,512,512])\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置訓練參數\n",
    "\n",
    "```\n",
    "參數名稱      型態                         說明\n",
    "logdir     : str                        : 儲存路徑\n",
    "epochs     : int                        : 訓練次數\n",
    "batch_size : int                        : 批次大小 (註:此設定需與image_dataset_from_directory的批次大小一致)\n",
    "optimizer  : str or tf.keras.optimizers : 優化函數\n",
    "loss       : str or tf.keras.loss       : 損失函數\n",
    "metrics    : list                       : 評估函數清單\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Create new the directory for training log !!!!!\n",
      "******************************\n",
      "Training new model...\n",
      "******************************\n",
      "checkpoint_path : log_fcn\\weights\n",
      "best_checkpoint : log_fcn\\weights.h5\n",
      "epochs          : 100\n",
      "initial_epoch   : 0\n",
      "batch_size      : 4\n",
      "optimizer       : {'name': 'Adam', 'learning_rate': 0.001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "loss            : categorical_crossentropy\n",
      "metrics         : ['Accuracy', <function DiceLoss at 0x000001CE68EF14C8>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mycnn.fcn.FCN8 at 0x1ce4b4e5408>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.setup_training(\n",
    "    'log_fcn',\n",
    "    epochs=100,\n",
    "    batch_size=train_dataset.batch_size,  # batch size depend on ImageGenerator\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"Accuracy\", losses.DiceLoss],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 開始訓練\n",
    "\n",
    "輸入參數分別為訓練資料集、驗證資料集的實例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "656/656 [==============================] - 168s 246ms/step - loss: 1.3736 - accuracy: 1.2352e-09 - DiceLoss: 0.4580 - val_loss: 1.2499 - val_accuracy: 0.0000e+00 - val_DiceLoss: 0.4152\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.24988, saving model to log_fcn\\weights.h5\n",
      "Epoch 2/100\n",
      "656/656 [==============================] - 165s 251ms/step - loss: 1.1668 - accuracy: 0.0000e+00 - DiceLoss: 0.3946 - val_loss: 1.2181 - val_accuracy: 0.0000e+00 - val_DiceLoss: 0.3951\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.24988 to 1.21811, saving model to log_fcn\\weights.h5\n",
      "Epoch 3/100\n",
      "656/656 [==============================] - 168s 256ms/step - loss: 1.1323 - accuracy: 0.0000e+00 - DiceLoss: 0.3883 - val_loss: 1.1601 - val_accuracy: 0.0000e+00 - val_DiceLoss: 0.4003\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.21811 to 1.16009, saving model to log_fcn\\weights.h5\n",
      "Epoch 4/100\n",
      "656/656 [==============================] - 171s 261ms/step - loss: 1.1037 - accuracy: 0.0000e+00 - DiceLoss: 0.3827 - val_loss: 1.1365 - val_accuracy: 0.0000e+00 - val_DiceLoss: 0.3764\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.16009 to 1.13654, saving model to log_fcn\\weights.h5\n",
      "Epoch 5/100\n",
      "656/656 [==============================] - 173s 264ms/step - loss: 1.0789 - accuracy: 0.0000e+00 - DiceLoss: 0.3775 - val_loss: 1.1225 - val_accuracy: 0.0000e+00 - val_DiceLoss: 0.3785\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.13654 to 1.12245, saving model to log_fcn\\weights.h5\n",
      "Epoch 6/100\n",
      "656/656 [==============================] - 176s 269ms/step - loss: 1.0528 - accuracy: 0.0000e+00 - DiceLoss: 0.3724 - val_loss: 1.1782 - val_accuracy: 0.0000e+00 - val_DiceLoss: 0.4093\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.12245\n",
      "Epoch 7/100\n",
      "656/656 [==============================] - 174s 265ms/step - loss: 1.0289 - accuracy: 0.0000e+00 - DiceLoss: 0.3678 - val_loss: 1.0803 - val_accuracy: 0.0000e+00 - val_DiceLoss: 0.4081\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.12245 to 1.08031, saving model to log_fcn\\weights.h5\n",
      "Epoch 8/100\n",
      "656/656 [==============================] - 176s 269ms/step - loss: 1.0032 - accuracy: 0.0000e+00 - DiceLoss: 0.3608 - val_loss: 1.0881 - val_accuracy: 0.0000e+00 - val_DiceLoss: 0.4364\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.08031\n",
      "Epoch 9/100\n",
      "656/656 [==============================] - 172s 263ms/step - loss: 0.9809 - accuracy: 0.0000e+00 - DiceLoss: 0.3551 - val_loss: 1.1076 - val_accuracy: 0.0000e+00 - val_DiceLoss: 0.4646\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.08031\n",
      "Epoch 10/100\n",
      "656/656 [==============================] - 160s 244ms/step - loss: 0.9566 - accuracy: 0.0000e+00 - DiceLoss: 0.3497 - val_loss: 1.1992 - val_accuracy: 0.0000e+00 - val_DiceLoss: 0.5109\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.08031\n",
      "Epoch 11/100\n",
      "656/656 [==============================] - 162s 247ms/step - loss: 0.9325 - accuracy: 0.0000e+00 - DiceLoss: 0.3439 - val_loss: 1.1014 - val_accuracy: 0.0000e+00 - val_DiceLoss: 0.4545\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.08031\n",
      "Epoch 12/100\n",
      "656/656 [==============================] - 160s 244ms/step - loss: 0.9077 - accuracy: 0.0000e+00 - DiceLoss: 0.3377 - val_loss: 1.0517 - val_accuracy: 0.0000e+00 - val_DiceLoss: 0.4333\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.08031 to 1.05174, saving model to log_fcn\\weights.h5\n",
      "Epoch 13/100\n",
      "656/656 [==============================] - 161s 245ms/step - loss: 0.8849 - accuracy: 0.0000e+00 - DiceLoss: 0.3318 - val_loss: 1.0604 - val_accuracy: 0.0000e+00 - val_DiceLoss: 0.4142\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.05174\n",
      "Epoch 14/100\n",
      "656/656 [==============================] - 160s 243ms/step - loss: 0.8565 - accuracy: 0.0000e+00 - DiceLoss: 0.3246 - val_loss: 0.9966 - val_accuracy: 0.0000e+00 - val_DiceLoss: 0.3703\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.05174 to 0.99656, saving model to log_fcn\\weights.h5\n",
      "Epoch 15/100\n",
      "656/656 [==============================] - 161s 245ms/step - loss: 0.8322 - accuracy: 0.0000e+00 - DiceLoss: 0.3183 - val_loss: 0.9994 - val_accuracy: 0.0000e+00 - val_DiceLoss: 0.3691\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.99656\n",
      "Epoch 16/100\n",
      "656/656 [==============================] - 158s 242ms/step - loss: 0.8073 - accuracy: 0.0000e+00 - DiceLoss: 0.3119 - val_loss: 1.0219 - val_accuracy: 0.0000e+00 - val_DiceLoss: 0.3680\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.99656\n",
      "Epoch 17/100\n",
      "656/656 [==============================] - 160s 243ms/step - loss: 0.7817 - accuracy: 3.8834e-08 - DiceLoss: 0.3058 - val_loss: 1.0545 - val_accuracy: 0.0000e+00 - val_DiceLoss: 0.3744\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.99656\n",
      "Epoch 18/100\n",
      "656/656 [==============================] - 159s 243ms/step - loss: 0.7615 - accuracy: 9.5048e-07 - DiceLoss: 0.3002 - val_loss: 1.1308 - val_accuracy: 0.0000e+00 - val_DiceLoss: 0.3858\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.99656\n",
      "Epoch 19/100\n",
      "656/656 [==============================] - 161s 246ms/step - loss: 0.7327 - accuracy: 3.8770e-06 - DiceLoss: 0.2915 - val_loss: 1.1609 - val_accuracy: 0.0000e+00 - val_DiceLoss: 0.3692\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.99656\n",
      "Epoch 20/100\n",
      "656/656 [==============================] - 161s 245ms/step - loss: 0.7037 - accuracy: 1.4669e-05 - DiceLoss: 0.2836 - val_loss: 1.3237 - val_accuracy: 0.0000e+00 - val_DiceLoss: 0.3856\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.99656\n",
      "Epoch 21/100\n",
      "656/656 [==============================] - 163s 249ms/step - loss: 0.6774 - accuracy: 5.4509e-05 - DiceLoss: 0.2762 - val_loss: 1.5307 - val_accuracy: 0.0000e+00 - val_DiceLoss: 0.3993\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.99656\n",
      "Epoch 22/100\n",
      "656/656 [==============================] - 165s 252ms/step - loss: 0.6567 - accuracy: 1.8033e-04 - DiceLoss: 0.2699 - val_loss: 1.7100 - val_accuracy: 0.0000e+00 - val_DiceLoss: 0.4736\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.99656\n",
      "Epoch 23/100\n",
      "656/656 [==============================] - 163s 249ms/step - loss: 0.6232 - accuracy: 3.9076e-04 - DiceLoss: 0.2591 - val_loss: 1.5610 - val_accuracy: 0.0000e+00 - val_DiceLoss: 0.4150\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.99656\n",
      "Epoch 24/100\n",
      "656/656 [==============================] - 161s 245ms/step - loss: 0.5942 - accuracy: 8.2961e-04 - DiceLoss: 0.2498 - val_loss: 1.4996 - val_accuracy: 3.1559e-06 - val_DiceLoss: 0.4033\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.99656\n",
      "Epoch 25/100\n",
      "656/656 [==============================] - 162s 247ms/step - loss: 0.5680 - accuracy: 0.0011 - DiceLoss: 0.2405 - val_loss: 1.4905 - val_accuracy: 3.7087e-05 - val_DiceLoss: 0.4240\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.99656\n",
      "Epoch 26/100\n",
      "656/656 [==============================] - 161s 246ms/step - loss: 0.5395 - accuracy: 0.0015 - DiceLoss: 0.2310 - val_loss: 1.3748 - val_accuracy: 6.8441e-05 - val_DiceLoss: 0.3665\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.99656\n",
      "Epoch 27/100\n",
      "656/656 [==============================] - 158s 241ms/step - loss: 0.5016 - accuracy: 0.0019 - DiceLoss: 0.2180 - val_loss: 1.4287 - val_accuracy: 1.1026e-04 - val_DiceLoss: 0.4036\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.99656\n",
      "Epoch 28/100\n",
      "656/656 [==============================] - 161s 245ms/step - loss: 0.4766 - accuracy: 0.0023 - DiceLoss: 0.2088 - val_loss: 1.3584 - val_accuracy: 1.2792e-04 - val_DiceLoss: 0.3897\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.99656\n",
      "Epoch 29/100\n",
      "656/656 [==============================] - 159s 242ms/step - loss: 0.4418 - accuracy: 0.0030 - DiceLoss: 0.1973 - val_loss: 1.5023 - val_accuracy: 2.7859e-04 - val_DiceLoss: 0.3833\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.99656\n",
      "Epoch 30/100\n",
      "656/656 [==============================] - 160s 243ms/step - loss: 0.4350 - accuracy: 0.0042 - DiceLoss: 0.1925 - val_loss: 1.6575 - val_accuracy: 4.5337e-04 - val_DiceLoss: 0.3865\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.99656\n",
      "Epoch 31/100\n",
      "656/656 [==============================] - 159s 243ms/step - loss: 0.4061 - accuracy: 0.0060 - DiceLoss: 0.1825 - val_loss: 1.5353 - val_accuracy: 7.9719e-04 - val_DiceLoss: 0.3700\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.99656\n",
      "Epoch 32/100\n",
      "656/656 [==============================] - 159s 243ms/step - loss: 0.3708 - accuracy: 0.0073 - DiceLoss: 0.1697 - val_loss: 1.6983 - val_accuracy: 8.8848e-04 - val_DiceLoss: 0.4038\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.99656\n",
      "Epoch 33/100\n",
      "656/656 [==============================] - 162s 246ms/step - loss: 0.3535 - accuracy: 0.0112 - DiceLoss: 0.1616 - val_loss: 1.6683 - val_accuracy: 0.0020 - val_DiceLoss: 0.3935\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.99656\n",
      "Epoch 34/100\n",
      "656/656 [==============================] - 161s 246ms/step - loss: 0.3323 - accuracy: 0.0152 - DiceLoss: 0.1534 - val_loss: 1.6736 - val_accuracy: 0.0013 - val_DiceLoss: 0.3793\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.99656\n",
      "Epoch 35/100\n",
      "656/656 [==============================] - ETA: 0s - loss: 0.3138 - accuracy: 0.0177 - DiceLoss: 0.1469"
     ]
    }
   ],
   "source": [
    "cnn.train_dataset(train_dataset, valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 繪製訓練過程曲線\n",
    "\n",
    "可以用來確認權重是否有收斂的趨勢、檢查是否有過擬合狀況"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.show_history([\"loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用測試資料來確認模型對於新資料的效能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.eval_dataset(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 預測單筆資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "file_path = train_image_paths[idx]\n",
    "print(file_path)\n",
    "image = cv2.imread(file_path)\n",
    "\n",
    "resized_image = cv2.resize(image, (224,224))\n",
    "plt.imshow(resized_image)\n",
    "plt.show()\n",
    "\n",
    "batch_one_image = np.expand_dims(resized_image, axis=0)\n",
    "print(batch_one_image.shape)\n",
    "\n",
    "pr_sc = cnn.predict(batch_one_image)\n",
    "for i in range(1):\n",
    "    plt.imshow(pr_sc[0,:,:,i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c369c7a0bd18095d69cc6bcfdfaf93c8e305f9651a20b05d28ea042855c27d0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tf2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
