{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception (GoogLeNet)\n",
    "\n",
    "在 VGG Net 中，我們可以發現 VGG 的 Block 是重複垂直連接 conv3x3 及 pool2x2 而組成，  \n",
    "雖然成功將神經網路做深，卻也產生出新的問題，像是權重數量過多導致訓練時間很長，模型會難以收斂等等，  \n",
    "也因為權重很多，更容易導致過擬合，因此 VGG 雖然準確度提高，卻也增加更多計算成本，多了很多不必要的運算。\n",
    "\n",
    "而 Inception 則是平行連接卷積層，每個卷積層都用不同的卷積核進行運算，其作用是加強神經網路對不同尺度特徵的理解。\n",
    "\n",
    "第一版用上了 conv5x5、conv3x3、conv1x1，在 VGG 範例中有提到大卷積核會增加計算成本，  \n",
    "為了減少因為卷積而增加的複雜度，使用 1x1 卷積運算並減少特徵圖的通道數量，用這種方式來減少計算量，同時也提高模型準確度。\n",
    "\n",
    "### Note\n",
    "\n",
    "Inception 就像是由好幾個小網路組成，因此又稱 Network in Network (NiN)，隨著不同版本的 Inception 出現，其結構也越來越複雜。\n",
    "\n",
    "### Reference\n",
    "\n",
    "[1] Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., & Anguelov, D. & Rabinovich, A.(2015). [Going deeper with convolutions.](https://arxiv.org/abs/1409.4842) In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 1-9).\n",
    "\n",
    "[2] Ioffe, S., & Szegedy, C. (2015). [Batch normalization: Accelerating deep network training by reducing internal covariate shift.](https://arxiv.org/abs/1502.03167) arXiv preprint arXiv:1502.03167.\n",
    "\n",
    "[3] Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., & Wojna, Z. (2016). [Rethinking the inception architecture for computer vision.](https://arxiv.org/abs/1512.00567) In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 2818-2826)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 引入相關python模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mycnn import GoogLeNet, InceptionV3\n",
    "from mycnn import utils\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自動下載貓狗資料集\n",
    "\n",
    "從 Microsoft Download Center 下載 Kaggle Cats and Dogs Dataset  \n",
    "會自動在工作路徑底下建立資料夾，並建立相關的資料集檔案結構  \n",
    "也會檢查路徑底下是否已經有建立完成檔案，避免重複下載及建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cats_vs_dogs_from_MSCenter('./datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用Keras API來建立Dataset實例\n",
    "\n",
    "利用Keras API中的`preprocessing`模組的`image_dataset_from_directory`  \n",
    "用此函數來建立貓狗的資料集，此函數將會回傳`tf.data.Dataset`的實例  \n",
    "接著使用`map`函式來重新縮放(正規化)資料區間至 [0, 1]\n",
    "\n",
    "#### tf.keras.preprocessing.image_dataset_from_directory\n",
    "\n",
    "```\n",
    "參數名稱            型態    說明\n",
    "directory        : str   : 資料路徑 (子資料夾為類別)\n",
    "image_size       : tuple : 影像大小\n",
    "batch_size       : int   : 批次大小\n",
    "label_mode       : str   : 標記模式 \"categorical\" (註:其他模式需要修改loss函數)\n",
    "validation_split : float : 分離驗證集的比例\n",
    "subset           : str   : 選擇訓練集 \"training\"、驗證集 \"validation\"\n",
    "seed             : int   : 亂數種子\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    './datasets/DogsVsCats/train',\n",
    "    image_size=(227,227),\n",
    "    batch_size=50,\n",
    "    label_mode=\"categorical\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=10\n",
    ")\n",
    "train_file_paths = train_dataset.file_paths\n",
    "train_dataset = train_dataset.map(lambda x, y: (x/255., y))\n",
    "\n",
    "\n",
    "valid_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    './datasets/DogsVsCats/train',\n",
    "    image_size=(227,227),\n",
    "    batch_size=50,\n",
    "    label_mode=\"categorical\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=10\n",
    ")\n",
    "valid_file_paths = valid_dataset.file_paths\n",
    "valid_dataset = valid_dataset.map(lambda x, y: (x/255., y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 檢查原始資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "file_path = valid_file_paths[idx]\n",
    "print(file_path)\n",
    "image = cv2.imread(file_path)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "resized_image = cv2.resize(image, (224,224))\n",
    "plt.imshow(resized_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入模型\n",
    "\n",
    "```\n",
    "參數名稱       型態    說明\n",
    "input_shape : tuple : 輸入影像形狀\n",
    "classes_num : int   : 輸出類別數量\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = GoogLeNet(classes_num=2)\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置訓練參數\n",
    "\n",
    "```\n",
    "參數名稱      型態                         說明\n",
    "logdir     : str                        : 儲存路徑\n",
    "epochs     : int                        : 訓練次數\n",
    "batch_size : int                        : 批次大小 (註:此設定需與image_dataset_from_directory的批次大小一致)\n",
    "optimizer  : str or tf.keras.optimizers : 優化函數\n",
    "loss       : str or tf.keras.loss       : 損失函數\n",
    "metrics    : list                       : 評估函數清單\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.setup_training(\n",
    "    'log_alexnet',\n",
    "    epochs=20,\n",
    "    batch_size=50,  # batch size depend on ImageGenerator\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "cnn.add_callback(\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=0.8, patience=10,\n",
    "        min_lr=0.00001,\n",
    "        verbose=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 開始訓練\n",
    "\n",
    "輸入參數分別為訓練資料集、驗證資料集的實例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.train_dataset(train_dataset, valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 繪製訓練過程曲線\n",
    "\n",
    "可以用來確認權重是否有收斂的趨勢、檢查是否有過擬合狀況"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.show_history([\"loss\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用測試資料來確認模型對於新資料的效能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.eval_dataset(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用confusion matrix來更進一步確認分類性能\n",
    "\n",
    "- 預測測試資料的分數 (基於softmax函數計算機率分布)\n",
    "- 使用`argmax`將分數轉成類別ID\n",
    "- 輸出分類報告 (印出confusion matrix、分類報告；輸出完整報表)\n",
    "- 繪製confusion matrix，分為recall、precision\n",
    "\n",
    "> Note:  \n",
    "recall: 召回率，在所有GT中，真正預測出TP的指標  \n",
    "precision: 精確率，在所有預測結果中，真正為TP的指標  \n",
    "(GT: 真實情況；TP: 正樣本)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    './datasets/DogsVsCats/train',\n",
    "    image_size=(227,227),\n",
    "    batch_size=20,\n",
    "    label_mode=\"categorical\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=10\n",
    ")\n",
    "pred_dataset = pred_dataset.map(lambda x, y: (x/255., y))\n",
    "\n",
    "pr_score = None\n",
    "pr_label = None\n",
    "gt_label = None\n",
    "for ind, batch_set in enumerate(pred_dataset):\n",
    "    batch_im, batch_gt = batch_set\n",
    "    batch_pr = cnn.pred(batch_im.numpy())\n",
    "    if ind == 0:\n",
    "        pr_score = batch_pr\n",
    "        pr_label = batch_pr.argmax(axis=-1)\n",
    "        gt_label = batch_gt.numpy().argmax(axis=-1)\n",
    "    else:\n",
    "        pr_score = np.concatenate([pr_score, batch_pr])\n",
    "        pr_label = np.concatenate([pr_label, batch_pr.argmax(axis=-1)])\n",
    "        gt_label = np.concatenate([gt_label, batch_gt.numpy().argmax(axis=-1)])\n",
    "\n",
    "target_names = [\"Cats\", \"Dogs\"]\n",
    "\n",
    "report = utils.export_classification_report(\n",
    "    gt_label, pr_label, pr_score,\n",
    "    target_names=target_names,\n",
    "    logpath=cnn.logdir\n",
    ")\n",
    "\n",
    "cm = report[\"confusion_matrix\"]\n",
    "cm_precision = cm/cm.sum(axis=0)\n",
    "cm_recall = cm/cm.sum(axis=1)\n",
    "utils.plot_confusion_matrix(cm_recall, target_names, cnn.logdir, title='Confusion Matrix (recall)')\n",
    "utils.plot_confusion_matrix(cm_precision, target_names, cnn.logdir, title='Confusion Matrix (precision)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 預測單筆資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "file_path = valid_file_paths[idx]\n",
    "print(file_path)\n",
    "image = cv2.imread(file_path)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "resized_image = cv2.resize(image, (224,224))\n",
    "plt.imshow(resized_image)\n",
    "plt.show()\n",
    "\n",
    "batch_one_image = np.expand_dims(resized_image, axis=0)\n",
    "batch_one_image = np.expand_dims(batch_one_image, axis=-1)\n",
    "print(batch_one_image.shape)\n",
    "\n",
    "pr_sc = cnn.predict(batch_one_image)\n",
    "pr_lb = pr_sc.argmax(axis=-1)\n",
    "print(\"Score:\")\n",
    "print(pr_sc[0])\n",
    "print(\"Label:\", pr_lb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c369c7a0bd18095d69cc6bcfdfaf93c8e305f9651a20b05d28ea042855c27d0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tf2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
