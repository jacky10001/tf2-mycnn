{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG Nets\n",
    "\n",
    "比起 AlexNet 使用更多卷積層來加深模型深度，加深的方式是使用重複的相似模塊 (block)，在當時是相當深的神經網路。\n",
    "\n",
    "VGG Block 的結構由幾個卷積層 (convolution) 再加上池化層 (pooling) 組成  \n",
    "每個卷積層都使用 3x3 卷積核 (kernal)、1x1 步長 (stride)，並進行填充，使特徵圖的大小一致  \n",
    "每個池化層使用大小及步長皆為 2x2，所以會將特徵圖大小縮減 2 倍  \n",
    "\n",
    "全連接層與 AlexNet 使用的全連接層相同\n",
    "\n",
    "### Note\n",
    "\n",
    "原本 AlexNet 有用到 conv11x11、conv5x5 等卷積核運算，使用大卷積核是非常耗計算效能，所以在 VGG 重複使用 conv3x3 就是為了提高計算效能，也同時加深網路。\n",
    "\n",
    "VGG 使用的卷積層硬生生地比 AlexNet 還多了很多，隨著 VGG Block 增加，權重數量也多了好幾倍，所以訓練時間會比較久，對於計算需求也較高，而且也因為權重變多，使模型難以收斂。\n",
    "\n",
    "### Reference\n",
    "\n",
    "[1] Simonyan, K., & Zisserman, A. (2014). [Very deep convolutional networks for large-scale image recognition.](https://arxiv.org/abs/1409.1556) arXiv preprint arXiv:1409.1556."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 引入相關python模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mycnn import VGG11, VGG13, VGG16, VGG19\n",
    "from mycnn import utils\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用Keras API來建立Dataset實例\n",
    "\n",
    "利用Keras API中的`preprocessing`模組的`image_dataset_from_directory`  \n",
    "用此函數來建立貓狗的資料集，此函數將會回傳`tf.data.Dataset`的實例  \n",
    "接著使用`map`函式來重新縮放(正規化)資料區間至 [0, 1]\n",
    "\n",
    "#### tf.keras.preprocessing.image_dataset_from_directory\n",
    "\n",
    "```\n",
    "參數名稱            型態    說明\n",
    "directory        : str   : 資料路徑 (子資料夾為類別)\n",
    "image_size       : tuple : 影像大小\n",
    "batch_size       : int   : 批次大小\n",
    "label_mode       : str   : 標記模式 \"categorical\" (註:其他模式需要修改loss函數)\n",
    "validation_split : float : 分離驗證集的比例\n",
    "subset           : str   : 選擇訓練集 \"training\"、驗證集 \"validation\"\n",
    "seed             : int   : 亂數種子\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    r'D:\\Datasets\\DogsVsCats\\train',\n",
    "    image_size=(227,227),\n",
    "    batch_size=50,\n",
    "    label_mode=\"categorical\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=10\n",
    ")\n",
    "train_file_paths = train_dataset.file_paths\n",
    "train_dataset = train_dataset.map(lambda x, y: (x/255., y))\n",
    "\n",
    "\n",
    "valid_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    r'D:\\Datasets\\DogsVsCats\\train',\n",
    "    image_size=(227,227),\n",
    "    batch_size=50,\n",
    "    label_mode=\"categorical\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=10\n",
    ")\n",
    "valid_file_paths = valid_dataset.file_paths\n",
    "valid_dataset = valid_dataset.map(lambda x, y: (x/255., y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 檢查原始資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "file_path = valid_file_paths[idx]\n",
    "print(file_path)\n",
    "image = cv2.imread(file_path)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "resized_image = cv2.resize(image, (224,224))\n",
    "plt.imshow(resized_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入模型\n",
    "\n",
    "```\n",
    "參數名稱       型態    說明\n",
    "input_shape : tuple : 輸入影像形狀\n",
    "classes_num : int   : 輸出類別數量\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = VGG16(classes_num=2)\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置訓練參數\n",
    "\n",
    "```\n",
    "參數名稱      型態                         說明\n",
    "logdir     : str                        : 儲存路徑\n",
    "epochs     : int                        : 訓練次數\n",
    "batch_size : int                        : 批次大小 (註:此設定需與image_dataset_from_directory的批次大小一致)\n",
    "optimizer  : str or tf.keras.optimizers : 優化函數\n",
    "loss       : str or tf.keras.loss       : 損失函數\n",
    "metrics    : list                       : 評估函數清單\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.setup_training(\n",
    "    'log_alexnet',\n",
    "    epochs=20,\n",
    "    batch_size=50,  # batch size depend on ImageGenerator\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "cnn.add_callback(\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=0.8, patience=10,\n",
    "        min_lr=0.00001,\n",
    "        verbose=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 開始訓練\n",
    "\n",
    "輸入參數分別為訓練資料集、驗證資料集的實例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.train_dataset(train_dataset, valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 繪製訓練過程曲線\n",
    "\n",
    "可以用來確認權重是否有收斂的趨勢、檢查是否有過擬合狀況"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.show_history([\"loss\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用測試資料來確認模型對於新資料的效能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.eval_dataset(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用confusion matrix來更進一步確認分類性能\n",
    "\n",
    "- 預測測試資料的分數 (基於softmax函數計算機率分布)\n",
    "- 使用`argmax`將分數轉成類別ID\n",
    "- 輸出分類報告 (印出confusion matrix、分類報告；輸出完整報表)\n",
    "- 繪製confusion matrix，分為recall、precision\n",
    "\n",
    "> Note:  \n",
    "recall: 召回率，在所有GT中，真正預測出TP的指標  \n",
    "precision: 精確率，在所有預測結果中，真正為TP的指標  \n",
    "(GT: 真實情況；TP: 正樣本)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    r'D:\\Datasets\\DogsVsCats\\train',\n",
    "    image_size=(227,227),\n",
    "    batch_size=20,\n",
    "    label_mode=\"categorical\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=10\n",
    ")\n",
    "pred_dataset = pred_dataset.map(lambda x, y: (x/255., y))\n",
    "\n",
    "pr_score = None\n",
    "pr_label = None\n",
    "gt_label = None\n",
    "for ind, batch_set in enumerate(pred_dataset):\n",
    "    batch_im, batch_gt = batch_set\n",
    "    batch_pr = cnn.pred(batch_im.numpy())\n",
    "    if ind == 0:\n",
    "        pr_score = batch_pr\n",
    "        pr_label = batch_pr.argmax(axis=-1)\n",
    "        gt_label = batch_gt.numpy().argmax(axis=-1)\n",
    "    else:\n",
    "        pr_score = np.concatenate([pr_score, batch_pr])\n",
    "        pr_label = np.concatenate([pr_label, batch_pr.argmax(axis=-1)])\n",
    "        gt_label = np.concatenate([gt_label, batch_gt.numpy().argmax(axis=-1)])\n",
    "\n",
    "target_names = [\"Cats\", \"Dogs\"]\n",
    "\n",
    "report = utils.export_classification_report(\n",
    "    gt_label, pr_label, pr_score,\n",
    "    target_names=target_names,\n",
    "    logpath=cnn.logdir\n",
    ")\n",
    "\n",
    "cm = report[\"confusion_matrix\"]\n",
    "cm_precision = cm/cm.sum(axis=0)\n",
    "cm_recall = cm/cm.sum(axis=1)\n",
    "utils.plot_confusion_matrix(cm_recall, target_names, cnn.logdir, title='Confusion Matrix (recall)')\n",
    "utils.plot_confusion_matrix(cm_precision, target_names, cnn.logdir, title='Confusion Matrix (precision)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 預測單筆資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "file_path = valid_file_paths[idx]\n",
    "print(file_path)\n",
    "image = cv2.imread(file_path)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "resized_image = cv2.resize(image, (224,224))\n",
    "plt.imshow(resized_image)\n",
    "plt.show()\n",
    "\n",
    "batch_one_image = np.expand_dims(resized_image, axis=0)\n",
    "batch_one_image = np.expand_dims(batch_one_image, axis=-1)\n",
    "print(batch_one_image.shape)\n",
    "\n",
    "pr_sc = cnn.predict(batch_one_image)\n",
    "pr_lb = pr_sc.argmax(axis=-1)\n",
    "print(\"Score:\")\n",
    "print(pr_sc[0])\n",
    "print(\"Label:\", pr_lb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c369c7a0bd18095d69cc6bcfdfaf93c8e305f9651a20b05d28ea042855c27d0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tf2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
