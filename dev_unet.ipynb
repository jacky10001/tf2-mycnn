{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 引入相關python模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mycnn import UNet\n",
    "from mycnn import utils\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mycnn import data\n",
    "data.generate_classification_dataset(\n",
    "    r'D:\\Datasets\\DogsVsCats\\train',\n",
    "    shuffle=True,\n",
    "    gray=True,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入UNet模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet(classes_num=1)\n",
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fn(dataset, **kwargs):\n",
    "    # 分離 dataset\n",
    "    path_x = dataset[\"in\"]\n",
    "    path_y = dataset[\"out\"]\n",
    "\n",
    "    # 讀取 image\n",
    "    x = tf.io.read_file(path_x)\n",
    "    x = tf.io.decode_image(x, channels=1, expand_animations=False)\n",
    "    y = tf.io.read_file(path_y)\n",
    "    y = tf.io.decode_image(y, channels=1, expand_animations=False)\n",
    "\n",
    "    # 對影像進行正規化，及增加影像通道\n",
    "    x = tf.cast(x, tf.float32) / 255.0\n",
    "    x = tf.expand_dims(x, axis=-1)\n",
    "    y = tf.cast(y, tf.float32) / 255.0\n",
    "    y = tf.expand_dims(y, axis=-1)\n",
    "\n",
    "    return x, y # 回傳資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tra_data_in = glob.glob(r\"data\\in\\*.png\")\n",
    "# tra_data_out = glob.glob(r\"data\\out\\*.png\")\n",
    "\n",
    "tra_data_in = [\"2007_001430.jpg\"]\n",
    "tra_data_out = [\"2007_001430.png\"]\n",
    "\n",
    "tra_data = {}\n",
    "tra_data[\"in\"] = tra_data_in\n",
    "tra_data[\"out\"] = tra_data_out\n",
    "\n",
    "autotune = tf.data.experimental.AUTOTUNE\n",
    "#-----------------------------------------------------------------------------#\n",
    "tra_ds = tf.data.Dataset.from_tensor_slices(tra_data)\n",
    "tra_ds = tra_ds.map(lambda ds: parse_fn(ds), num_parallel_calls=autotune)\n",
    "tra_ds = tra_ds.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "             loss=\"mse\")\n",
    "unet.fit(tra_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c369c7a0bd18095d69cc6bcfdfaf93c8e305f9651a20b05d28ea042855c27d0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tf2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
