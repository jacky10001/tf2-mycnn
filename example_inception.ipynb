{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 引入相關python模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mycnn import InceptionV1\n",
    "from mycnn import utils\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "inception_v1 = InceptionV1(classes_num=2)\n",
    "inception_v1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用Keras API來建立Dataset實例\n",
    "\n",
    "利用Keras API中的`preprocessing`模組的`image_dataset_from_directory`  \n",
    "用此函數來建立貓狗的資料集，此函數將會回傳`tf.data.Dataset`的實例  \n",
    "接著使用`map`函式來重新縮放(正規化)資料區間至 [0, 1]\n",
    "\n",
    "#### tf.keras.preprocessing.image_dataset_from_directory\n",
    "\n",
    "```\n",
    "參數名稱            型態    說明\n",
    "directory        : str   : 資料路徑 (子資料夾為類別)\n",
    "image_size       : tuple : 影像大小\n",
    "batch_size       : int   : 批次大小\n",
    "label_mode       : str   : 標記模式 \"categorical\" (註:其他模式需要修改loss函數)\n",
    "validation_split : float : 分離驗證集的比例\n",
    "subset           : str   : 選擇訓練集 \"training\"、驗證集 \"validation\"\n",
    "seed             : int   : 亂數種子\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    r'D:\\Datasets\\DogsVsCats\\train',\n",
    "    image_size=(224,224),\n",
    "    batch_size=20,\n",
    "    label_mode=\"categorical\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=10\n",
    ")\n",
    "train_file_paths = train_dataset.file_paths\n",
    "train_dataset.map(lambda x, y: (x/255., y))\n",
    "\n",
    "\n",
    "valid_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    r'D:\\Datasets\\DogsVsCats\\train',\n",
    "    image_size=(224,224),\n",
    "    batch_size=20,\n",
    "    label_mode=\"categorical\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=10\n",
    ")\n",
    "valid_file_paths = valid_dataset.file_paths\n",
    "valid_dataset.map(lambda x, y: (x/255., y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入Inception模型\n",
    "\n",
    "```\n",
    "參數名稱       型態    說明\n",
    "input_shape : tuple : 輸入影像形狀\n",
    "classes_num : int   : 輸出類別數量\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception = InceptionV1(classes_num=2)\n",
    "inception.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置訓練參數\n",
    "\n",
    "```\n",
    "參數名稱      型態                         說明\n",
    "logdir     : str                        : 儲存路徑\n",
    "epochs     : int                        : 訓練次數\n",
    "batch_size : int                        : 批次大小 (註:此設定需與image_dataset_from_directory的批次大小一致)\n",
    "optimizer  : str or tf.keras.optimizers : 優化函數\n",
    "loss       : str or tf.keras.loss       : 損失函數\n",
    "metrics    : list                       : 評估函數清單\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception.setup_training(\n",
    "    'log_inception',\n",
    "    epochs=10,\n",
    "    batch_size=20,  # batch size depend on `image_dataset_from_directory`\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "inception.add_callback(\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=0.1, patience=2,\n",
    "        min_lr=0.00001,\n",
    "        verbose=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 開始訓練\n",
    "\n",
    "輸入參數分別為訓練資料集、驗證資料集的實例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception.train_dataset(train_dataset, valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 繪製訓練過程曲線\n",
    "\n",
    "可以用來確認權重是否有收斂的趨勢、檢查是否有過擬合狀況"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception.show_history([\"loss\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用測試資料來確認模型對於新資料的效能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception.eval_dataset(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用confusion matrix來更進一步確認分類性能\n",
    "\n",
    "- 預測測試資料的分數 (基於softmax函數計算機率分布)\n",
    "- 使用`argmax`將分數轉成類別ID\n",
    "- 輸出分類報告 (印出confusion matrix、分類報告；輸出完整報表)\n",
    "- 繪製confusion matrix，分為recall、precision\n",
    "\n",
    "> Note:  \n",
    "recall: 召回率，在所有GT中，真正預測出TP的指標  \n",
    "precision: 精確率，在所有預測結果中，真正為TP的指標  \n",
    "(GT: 真實情況；TP: 正樣本)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    r'D:\\Datasets\\DogsVsCats\\train',\n",
    "    image_size=(224,224),\n",
    "    batch_size=20,\n",
    "    label_mode=\"categorical\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=10\n",
    ")\n",
    "pred_dataset = pred_dataset.map(lambda x, y: (x/255., y))\n",
    "\n",
    "pr_score = None\n",
    "pr_label = None\n",
    "gt_label = None\n",
    "for ind, batch_set in enumerate(pred_dataset):\n",
    "    batch_im, batch_gt = batch_set\n",
    "    batch_pr = inception.pred(batch_im.numpy())\n",
    "    if ind == 0:\n",
    "        pr_score = batch_pr\n",
    "        pr_label = batch_pr.argmax(axis=-1)\n",
    "        gt_label = batch_gt.numpy().argmax(axis=-1)\n",
    "    else:\n",
    "        pr_score = np.concatenate([pr_score, batch_pr])\n",
    "        pr_label = np.concatenate([pr_label, batch_pr.argmax(axis=-1)])\n",
    "        gt_label = np.concatenate([gt_label, batch_gt.numpy().argmax(axis=-1)])\n",
    "\n",
    "target_names = [\"Cats\", \"Dogs\"]\n",
    "\n",
    "report = utils.export_classification_report(\n",
    "    gt_label, pr_label, pr_score,\n",
    "    target_names=target_names,\n",
    "    logpath=inception.logdir\n",
    ")\n",
    "\n",
    "cm = report[\"confusion_matrix\"]\n",
    "cm_precision = cm/cm.sum(axis=0)\n",
    "cm_recall = cm/cm.sum(axis=1)\n",
    "utils.plot_confusion_matrix(cm_recall, target_names, inception.logdir, title='Confusion Matrix (recall)')\n",
    "utils.plot_confusion_matrix(cm_precision, target_names, inception.logdir, title='Confusion Matrix (precision)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c369c7a0bd18095d69cc6bcfdfaf93c8e305f9651a20b05d28ea042855c27d0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tf2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
